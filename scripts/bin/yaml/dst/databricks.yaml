type: DATABRICKS_DELTALAKE

host: "<hostname>"
port: "<port>"

# connection config section 
url: "jdbc:spark://<host>:<port>/<database-name>;transportMode=http;ssl=1;httpPath=<http-path>;AuthMech=3" # This url can be copied from databricks cluster info page

username: "<username>"                                     # values : token or valid username 
password: "<password>"                                     # values : token value or valid password
max-connections: 30

#lob-store-path: "/LOB_STORAGE"

# stage config section
stage:
  type: S3
  root-dir: "<stage-directory>"    #specify a directory in S3 which can be used to stage bulk-load files. e.g. replicate-stage/databricks-stage
  conn-url: "<s3 bucket name>"     # specify bucket name e.g. replicate-stage 
  key-id: "<S3 access key>"        #S3 access key
  secret-key: "<S3 secret key>"    #S3 secret key
#  session-info:
#    key-id: "<s3 seesion user key>"
#    secret-key: "<s3 session user secret key>"
#    session-duration-s: 3600
#  file-format: PARQUET/CSV #default is PARQUET

#max-retries: 100
#retry-wait-duration-ms: 1000
