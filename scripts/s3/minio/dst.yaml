type: S3

access-key: '${DSTDB_ACCESS_KEY:-${DSTDB_ARC_USER}}'
secret-key: '${DSTDB_SECRET:-${DSTDB_ARC_PW}}'

# bucket name.service-endppoint = new URL
# for exmaple http://arcdst.minio:9000 will be used from the below
# if IP is used, then bucket name will not be used
bucket: '${DSTDB_ARC_USER}'
endpoint:
  service-endpoint: '${DSTDB_URL:-http://${DSTDB_IP:-${DSTDB_HOST}}:${DSTDB_PORT}}' 
  #signingRegion: us-east-1

# this must match mc create bucket/name from dst.init.roo.sh script
# cannot trailing / in the name
root: '${DSTDB_ARC_USER}/${DSTDB_DB}'

#directory where CSV files will be staged before uploading to S3
stage:
  type: SHARED_FS
  root-dir: '${CFG_DIR}/stage' 
file-format: CSV  # CSV | JSON

max-connections: 5
max-retries: 1
  
