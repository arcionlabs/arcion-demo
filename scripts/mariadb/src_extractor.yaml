snapshot:
  threads: 16
  fetch-size-rows: 15_000

# min-job-size-rows: 1_000_000
# max-jobs-per-chunk: 32

  _traceDBTasks: true
#  fetch-user-roles: true

#  per-table-config:
#  - catalog: tpch
#    tables:
#      ORDERS:
#        num-jobs: 1
#      LINEITEM:
#        row-identifier-key: [L_ORDERKEY]
#        split-key: l_orderkey
#        split-hints:
#          row-count-estimate: 15000
#          split-key-min-value: 1
#          split-key-max-value: 60_000
#      ORDERS1:
#        row-identifier-key: [O_ORDERKEY]

realtime:
  threads: 4
  fetch-size-rows: 10_000
  fetch-duration-per-extractor-slot-s: 3
  _traceDBTasks: true
  ddl-replication:
    enable: true                 # This config enables detection of DDLs fire on source. Supported values are true/false.
    ddl-replication-mode: INLINE # Default is REINIT mode. Supported modes REINIT and INLINE.
                                  # INLINE MODE : We will parse cdc logs generated by source and apply them to target.
                                  # If we are not able to parse ddl or target does not support a particular ddl then we fall back to the REINIT method and do reinitialization of that table.
                                  # REINIT MODE : After every x seconds (governed by detect-ddl-interval config below) we will fetch schemas from source and compare with target to detect DDLs.
                                  # Once the ddl is detected, the table needs to be reinitialized. If REINIT mode is used please set skip-tables-on-failures: true in applier config.
    detect-ddl-interval: 60       # This config sets the value of DDL detection interval in seconds E.g if set to 600 then DDLs will be detected after every 600 seconds.
                                  # This is only used when ddl-replication-mode is REINT. If DDLs are rare it is recommended to set large value.

  heartbeat:
    enable: true
    catalog: arcsrc
    interval-ms: 10000

delta-snapshot:
  #threads: 32
  #fetch-size-rows: 10_000

  #min-job-size-rows: 1_000_000
  max-jobs-per-chunk: 32
  _max-delete-jobs-per-chunk: 32

  # each table has column names ts that is updated
  delta-snapshot-key: ts
  delta-snapshot-interval: 10
  delta-snapshot-delete-interval: 10
  _traceDBTasks: true
  replicate-deletes: false

